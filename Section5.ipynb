{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/straxFromIbr/NLP_with_BERT/blob/main/Section5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbK-dDK5_usQ"
      },
      "outputs": [],
      "source": [
        "!pip install -U pip 2>&1 >/dev/null\n",
        "!pip install transformers==4.5.0 fugashi==1.1.0 ipadic==1.0.0 2>&1 >/dev/null \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKkNQDme_8Fs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertJapaneseTokenizer, BertForMaskedLM\n",
        "\n",
        "MODEL_NAME = \"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n",
        "bert_mlm = BertForMaskedLM.from_pretrained(MODEL_NAME)\n",
        "bert_mlm = bert_mlm.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRESV21MBH_m"
      },
      "outputs": [],
      "source": [
        "text = '今日は[MASK]へ行く。'\n",
        "tokens = tokenizer.tokenize(text)\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2ifIU3zBjk-"
      },
      "outputs": [],
      "source": [
        "input_ids = tokenizer.encode(text, return_tensors='pt').cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = bert_mlm(input_ids=input_ids)\n",
        "    scores = output.logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldX6TKIrBv6K"
      },
      "outputs": [],
      "source": [
        "mask_position = input_ids[0].tolist().index(4)\n",
        "id_best = scores[0, mask_position].argmax(-1).tolist()\n",
        "token_best = tokenizer.convert_ids_to_tokens(id_best)\n",
        "token_best = token_best.replace('##', '')\n",
        "\n",
        "text = text.replace('[MASK]', token_best)\n",
        "text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu2AHFrTCrLF"
      },
      "outputs": [],
      "source": [
        "def predict_mask_topk(text, tokenizer, bert_mlm, num_topk):\n",
        "    \"\"\"\n",
        "    入力テキスト中の1つのMASKをスコアが最も高い単語で埋める\n",
        "    \"\"\"\n",
        "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
        "    input_ids = input_ids.cuda()\n",
        "    with torch.no_grad():\n",
        "        output = bert_mlm(input_ids=input_ids)\n",
        "    scores = output.logits\n",
        "\n",
        "    mask_position = input_ids[0].tolist().index(4) # `4`は'[MASK]'のID\n",
        "    topk = scores[0, mask_position].topk(num_topk)\n",
        "    scores_topk = topk.values.cpu().numpy()\n",
        "\n",
        "    ids_topk = topk.indices\n",
        "    tokens_topk = tokenizer.convert_ids_to_tokens(ids_topk)\n",
        "\n",
        "    text_topk = []\n",
        "    for token in tokens_topk:\n",
        "        token = token.replace('##', '')\n",
        "        text_topk.append(text.replace('[MASK]', token, 1))\n",
        "    \n",
        "    return text_topk, scores_topk\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRgKxvVyEOCT"
      },
      "outputs": [],
      "source": [
        "text = '今日は[MASK]へ行く。'\n",
        "text_topk, _ = predict_mask_topk(text, tokenizer, bert_mlm, 20)\n",
        "print(*text_topk, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfATXwS3Fm9U"
      },
      "outputs": [],
      "source": [
        "def greedy_prediction(text, tokenizer, bert_mlm):\n",
        "    \"\"\"\n",
        "    貪欲法による複数MASKの穴埋め。\n",
        "    先頭のMASKからスコアが高いものでうめてく\n",
        "    \"\"\"\n",
        "    for _ in range(text.count('[MASK]')):\n",
        "        text = predict_mask_topk(text, tokenizer, bert_mlm, 1)[0][0]\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjxZy7omIP4d"
      },
      "outputs": [],
      "source": [
        "text = '明日は[MASK]が[MASK]かな。'\n",
        "print(predict_mask_topk(text, tokenizer, bert_mlm, 1)[0][0])\n",
        "print(greedy_prediction(text, tokenizer, bert_mlm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nvue4_c4Jk66"
      },
      "outputs": [],
      "source": [
        "def beam_search(text, tokenizer, bert_mlm, num_topk):\n",
        "    \"\"\"\n",
        "    ビームサーチでMASKを埋める\n",
        "    \"\"\"\n",
        "    num_mask = text.count('[MASK]')\n",
        "    text_topk = [text]\n",
        "    scores_topk = np.array([0])\n",
        "    for _ in range(num_mask):\n",
        "        text_candidates = []\n",
        "        score_candidates = []\n",
        "        for text_mask, score in zip(text_topk, scores_topk):\n",
        "            text_topk_inner, scores_topk_inner = predict_mask_topk(\n",
        "                text_mask, tokenizer, bert_mlm, num_topk\n",
        "            )\n",
        "            text_candidates.extend(text_topk_inner)\n",
        "            score_candidates.append(score + scores_topk_inner)\n",
        "        score_candidates = np.hstack(score_candidates)\n",
        "        idx_list = score_candidates.argsort()[::-1][:num_topk]\n",
        "        text_topk = [text_candidates[idx] for idx in idx_list]\n",
        "        scores_topk = score_candidates[idx_list]\n",
        "    return text_topk\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPYCOh0xKYS4"
      },
      "outputs": [],
      "source": [
        "text = '今日は[MASK][MASK]へ行く。'\n",
        "print('# with beam search')\n",
        "print(*beam_search(text, tokenizer, bert_mlm, 10), sep='\\n')\n",
        "print('# with greedy method')\n",
        "print(greedy_prediction(text, tokenizer, bert_mlm))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_YWnzhcLsHk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPnNMon85pWRDnyLFWAc2lI",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Untitled14.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
