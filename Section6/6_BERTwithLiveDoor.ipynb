{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wBxFdW2xuUC5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "ON_COLAB = \"COLAB_GPU\" in os.environ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "K7bFjPx6Dooh"
      },
      "outputs": [],
      "source": [
        "from datetime import date\n",
        "modelpath = f\"./model_{date.today().strftime('%y-%m-%d')}\"\n",
        "if ON_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    modelpath = '/content/drive/MyDrive/ColabFolder/NLPwithBERT/Section6/model'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYl8n5pFuUC7"
      },
      "source": [
        "## ライブラリインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4E3VgAYuUC8"
      },
      "outputs": [],
      "source": [
        "if ON_COLAB:\n",
        "    !pip install -U pip 2>&1 >/dev/null\n",
        "    !pip install \\\n",
        "        transformers==4.5.0 \\\n",
        "        fugashi==1.1.0 \\\n",
        "        ipadic==1.0.0  \\\n",
        "        pytorch-lightning==1.2.7 2>&1 >/dev/null "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYgM7tFAuUC8"
      },
      "source": [
        "## データセットのダウンロードと解凍"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPlHDxzzuUC9"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('ldcc-20140209.tar.gz'):\n",
        "    ! wget 'https://rondhuit.com/download/ldcc-20140209.tar.gz'  >/dev/null 2>&1\n",
        "    ! tar -zxf 'ldcc-20140209.tar.gz'  >/dev/null 2>&1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwhU2WoxuUC9"
      },
      "outputs": [],
      "source": [
        "! head -n7 './text/it-life-hack/it-life-hack-6342280.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LTrNN0muUC9"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import BertJapaneseTokenizer, BertForSequenceClassification\n",
        "\n",
        "MODEL_NAME = \"cl-tohoku/bert-base-japanese-whole-word-masking\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bpt79cKuUC9"
      },
      "outputs": [],
      "source": [
        "# ラベルリスト\n",
        "category_list = [\n",
        "    \"dokujo-tsushin\",\n",
        "    \"it-life-hack\",\n",
        "    \"kaden-channel\",\n",
        "    \"livedoor-homme\",\n",
        "    \"movie-enter\",\n",
        "    \"peachy\",\n",
        "    \"smax\",\n",
        "    \"sports-watch\",\n",
        "    \"topic-news\",\n",
        "]\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MOajaKDXuUC-"
      },
      "outputs": [],
      "source": [
        "# データ整形\n",
        "max_length = 128\n",
        "dataset_for_loader = []\n",
        "for label, category in enumerate(tqdm(category_list)):\n",
        "    for file in glob.glob(f\"./text/{category}/{category}*\"):\n",
        "        lines = open(file).read().splitlines()\n",
        "        text = \"\\n\".join(lines[3:])\n",
        "        encoding = tokenizer(\n",
        "            text,\n",
        "            max_length=max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "        )\n",
        "        encoding[\"labels\"] = label\n",
        "        encoding = {k: torch.tensor(v) for k, v in encoding.items()}\n",
        "        dataset_for_loader.append(encoding)\n",
        "\n",
        "print(dataset_for_loader[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VeSw0GFVuUC-"
      },
      "outputs": [],
      "source": [
        "random.shuffle(dataset_for_loader)\n",
        "n = len(dataset_for_loader)\n",
        "n_train = int(0.6 * n)\n",
        "n_val = int(0.2 * n)\n",
        "dataset_train = dataset_for_loader[:n_train]\n",
        "dataset_val = dataset_for_loader[n_train : n_train + n_val]\n",
        "dataset_test = dataset_for_loader[n_train + n_val :]\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
        "dataloader_val = DataLoader(dataset_val, batch_size=256)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=256)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ85ghHZuUC_"
      },
      "source": [
        "## PyTorch Lightningで文章分類モデルを構築する"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceQ0_D0ruUC_"
      },
      "outputs": [],
      "source": [
        "class BertForSequenceClassification_pl(pl.LightningModule):\n",
        "    def __init__(self, model_name, num_labels, lr) -> None:\n",
        "        \"\"\"\n",
        "        model_name: モデルの名前\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        # `__init__`の引数を保存する！便利！\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.bert_sc = BertForSequenceClassification.from_pretrained(\n",
        "            model_name, num_labels=num_labels\n",
        "        )\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        # 各学習ステップで呼ばれる関数\n",
        "            - 損失を記録し、返す\n",
        "        \"\"\"\n",
        "        output = self.bert_sc(**batch)\n",
        "        loss = output.loss\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        # こちらは検証ステップで呼ばれる関数\n",
        "            - 損失を記録し、返す\n",
        "        \"\"\"\n",
        "        output = self.bert_sc(**batch)\n",
        "        loss = output.loss\n",
        "        self.log(\"val_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        \"\"\"\n",
        "        # こちらはテストステップで呼ばれる関数\n",
        "            - ラベルの正解率を求めて記録する\n",
        "        \"\"\"\n",
        "        labels = batch.pop(\"labels\")\n",
        "        output = self.bert_sc(**batch)\n",
        "        labels_predicted = output.logits.argmax(-1)\n",
        "        num_correct = (labels_predicted == labels).sum().item()\n",
        "        # 正解率を求める\n",
        "        accurancy = num_correct / labels.size(0)\n",
        "        self.log(\"accurancy\", accurancy)\n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"\n",
        "        オプティマイザを返す。\n",
        "        オプティマイザにはAdamを使用しモデルのパラメータと学習率を渡す\n",
        "        \"\"\"\n",
        "        return torch.optim.Adam(self.parameters() ,lr=self.hparams.lr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNR5TcSSuUDA"
      },
      "source": [
        "## CheckpointのCallbackとTrainerの作成\n",
        "- kerasとノリが似てる"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVc08_RXuUDA"
      },
      "outputs": [],
      "source": [
        "checkpoint = pl.callbacks.ModelCheckpoint(\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_top_k=1,\n",
        "    save_weights_only=True,\n",
        "    dirpath=modelpath,\n",
        ")\n",
        "\n",
        "if ON_COLAB:\n",
        "    trainer = pl.Trainer(\n",
        "        gpus=1,\n",
        "        max_epochs=10,\n",
        "        callbacks=[checkpoint],\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "TVURRFO0vCOB"
      },
      "outputs": [],
      "source": [
        "# モデル作成\n",
        "model = BertForSequenceClassification_pl(MODEL_NAME, num_labels=9, lr=1e-5)\n",
        "\n",
        "# 訓練(ファインチューニング)する\n",
        "hist = trainer.fit(model, dataloader_train, dataloader_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZUJKYnrvWQU"
      },
      "outputs": [],
      "source": [
        "best_model_path = checkpoint.best_model_path\n",
        "print('最良モデルのチェックポイント', best_model_path)\n",
        "print('裁量モデルでの検証データに対する損失', checkpoint.best_model_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PhOurknElC7"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./lightning_logs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "6_BERTwithLiveDoor.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "90de77d5f2332149b175b580a4a3bb73f0707314cd3d07e31835a300405106d8"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('pytorch': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
