{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "ON_COLAB = \"COLAB_GPU\" in os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ON_COLAB:\n",
    "    !pip install -U pip 2>&1 >/dev/null\n",
    "    !pip install \\\n",
    "        transformers==4.5.0 \\\n",
    "        fugashi==1.1.0 \\\n",
    "        ipadic==1.0.0 2>&1 \\\n",
    "        torch-lightning==1.2.7 >/dev/null "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットのダウンロードと解凍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('ldcc-20140209.tar.gz'):\n",
    "    ! wget 'https://rondhuit.com/download/ldcc-20140209.tar.gz'  >/dev/null 2>&1\n",
    "    ! tar -zxf 'ldcc-20140209.tar.gz'  >/dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n7 './text/it-life-hack/it-life-hack-6342280.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertJapaneseTokenizer, BertForSequenceClassification\n",
    "\n",
    "MODEL_NAME = \"cl-tohoku/bert-base-japanese-whole-word-masking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルリスト\n",
    "category_list = [\n",
    "    \"dokujo-tsushin\",\n",
    "    \"it-life-hack\",\n",
    "    \"kaden-channel\",\n",
    "    \"livedoor-homme\",\n",
    "    \"movie-enter\",\n",
    "    \"peachy\",\n",
    "    \"smax\",\n",
    "    \"sports-watch\",\n",
    "    \"topic-news\",\n",
    "]\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained(MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ整形\n",
    "max_length = 128\n",
    "dataset_for_loader = []\n",
    "for label, category in enumerate(tqdm(category_list)):\n",
    "    for file in glob.glob(f\"./text/{category}/{category}*\"):\n",
    "        lines = open(file).read().splitlines()\n",
    "        text = \"\\n\".join(lines[3:])\n",
    "        encoding = tokenizer(\n",
    "            text,\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        encoding[\"labels\"] = label\n",
    "        encoding = {k: torch.tensor(v) for k, v in encoding.items()}\n",
    "        dataset_for_loader.append(encoding)\n",
    "\n",
    "print(dataset_for_loader[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataset_for_loader)\n",
    "n = len(dataset_for_loader)\n",
    "n_train = int(0.6 * n)\n",
    "n_val = int(0.2 * n)\n",
    "dataset_train = dataset_for_loader[:n_train]\n",
    "dataset_val = dataset_for_loader[n_train : n_train + n_val]\n",
    "dataset_test = dataset_for_loader[n_train + n_val :]\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=256)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=256)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Lightningで文章分類モデルを構築する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForSequenceClassification_pl(pl.LightningModule):\n",
    "    def __init__(self, model_name, num_labels, lr) -> None:\n",
    "        \"\"\"\n",
    "        model_name: モデルの名前\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # `__init__`の引数を保存する！便利！\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.bert_sc = BertForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=num_labels\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        # 各学習ステップで呼ばれる関数\n",
    "            - 損失を記録し、返す\n",
    "        \"\"\"\n",
    "        output = self.bert_sc(**batch)\n",
    "        loss = output.loss\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        # こちらは検証ステップで呼ばれる関数\n",
    "            - 損失を記録し、返す\n",
    "        \"\"\"\n",
    "        output = self.bert_sc(**batch)\n",
    "        loss = output.loss\n",
    "        self.log(\"valid_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        \"\"\"\n",
    "        # こちらはテストステップで呼ばれる関数\n",
    "            - ラベルの正解率を求めて記録する\n",
    "        \"\"\"\n",
    "        labels = batch.pop(\"labels\")\n",
    "        output = self.bert_sc(**batch)\n",
    "        labels_predicted = output.logits.argmax(-1)\n",
    "        num_correct = (labels_predicted == labels).sum().item()\n",
    "        # 正解率を求める\n",
    "        accurancy = num_correct / labels.size(0)\n",
    "        self.log(\"accurancy\", accurancy)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"\n",
    "        オプティマイザを返す。\n",
    "        オプティマイザにはAdamを使用しモデルのパラメータと学習率を渡す\n",
    "        \"\"\"\n",
    "        return torch.optim.Adam(self.parameters() ,lr=self.hparams.lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CheckpointのCallbackとTrainerの作成\n",
    "- kerasとノリが似てる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = pl.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    save_top_k=1,\n",
    "    save_weights_only=True,\n",
    "    dirpath=\"model/\",\n",
    ")\n",
    "\n",
    "if ON_COLAB:\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=1,\n",
    "        max_epochs=10,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90de77d5f2332149b175b580a4a3bb73f0707314cd3d07e31835a300405106d8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
